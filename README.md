# AImee - AI Tour Guide with Real-time Voice

AImee is an intelligent tour guide application that provides real-time voice conversations using LiveKit and OpenAI. Users can have natural conversations with AImee about locations, landmarks, and travel information through their mobile device.

## ğŸ¯ Current Status: Phase 6

**Real-time Voice Conversations** - Complete voice-to-voice interaction using LiveKit Agents framework with OpenAI integration.

### Features
- âœ… Real-time speech-to-speech conversations
- âœ… Natural tour guide personality
- âœ… Automatic greeting when users join
- âœ… Mute/unmute controls for privacy
- âœ… Low-latency audio processing
- âœ… Cross-platform mobile support (iOS/Android)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Mobile App    â”‚    â”‚  Python Agent  â”‚    â”‚ Node.js Backend â”‚
â”‚  (React Native) â”‚â—„â”€â”€â–ºâ”‚ (LiveKit Agent) â”‚    â”‚ (Multi-Agent)   â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Voice UI      â”‚    â”‚ â€¢ Speech-to-Textâ”‚    â”‚ â€¢ OpenAI API    â”‚
â”‚ â€¢ LiveKit Clientâ”‚    â”‚ â€¢ LLM Processingâ”‚    â”‚ â€¢ Agent Routing â”‚
â”‚ â€¢ Mute Controls â”‚    â”‚ â€¢ Text-to-Speechâ”‚    â”‚ â€¢ Conversation  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   LiveKit Cloud â”‚
                    â”‚ (Voice Transport)â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites
- Docker and Docker Compose
- Node.js 18+ and npm
- Physical iOS/Android device (required for voice functionality)
- OpenAI API key
- LiveKit account and credentials

### 1. Environment Setup

Create a `.env` file in the project root:

```bash
# LiveKit Configuration
LIVEKIT_URL=wss://your-project.livekit.cloud
LIVEKIT_API_KEY=your_api_key
LIVEKIT_API_SECRET=your_api_secret

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key
OPENAI_MODEL=gpt-4o-mini

# Room Configuration
ROOM_NAME=aimee-phase1
PARTICIPANT_IDENTITY=aimee-agent
```

### 2. Start the Voice Agent

```bash
# Start the Python voice agent
docker compose up agent

# Or rebuild from scratch
docker compose down && docker compose build --no-cache agent && docker compose up agent
```

### 3. Run the Mobile App

```bash
cd mobile

# Install dependencies
npm install

# Start development server
npx expo start

# Deploy to physical device (required for voice)
npx expo run:ios     # iOS
npx expo run:android # Android
```

### 4. Test Voice Conversation

1. Open the mobile app on your physical device
2. Tap "Connect to AImee"
3. AImee will automatically greet you
4. Use "Mute/Unmute" button to control your microphone
5. Have a natural conversation about travel and locations!

## ğŸ“± Mobile App Usage

### Voice Controls
- **Connect to AImee**: Join the LiveKit room and start conversation
- **ğŸ¤ Mute**: Disable microphone (AImee can't hear you)
- **ğŸ”‡ Unmute**: Enable microphone (AImee can hear you)
- **Disconnect**: Leave the room and end conversation

### Status Indicators
- **Listening**: Microphone is active, AImee can hear you
- **Muted**: Microphone is disabled for privacy
- **Connected**: Successfully connected to AImee's voice agent
- **Connecting**: Establishing connection to LiveKit room

## ğŸ› ï¸ Development

### Project Structure
```
aimee-livekit-sesame-aitourguide/
â”œâ”€â”€ mobile/                      # React Native mobile app
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ screens/VoiceScreen.tsx    # Main voice interface
â”‚   â”‚   â””â”€â”€ lib/config.ts              # LiveKit configuration
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ agent/                   # Python voice agent
â”‚   â”‚   â”œâ”€â”€ aimee_agent.py            # LiveKit Agents implementation
â”‚   â”‚   â”œâ”€â”€ requirements.txt          # Python dependencies
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â””â”€â”€ backend/                 # Node.js backend (legacy)
â”‚       â”œâ”€â”€ src/index.ts              # Express server
â”‚       â””â”€â”€ package.json
â”œâ”€â”€ docker-compose.yml           # Service orchestration
â””â”€â”€ .env                        # Environment configuration
```

### Running Individual Services

**Python Voice Agent**:
```bash
docker compose up agent
```

**Node.js Backend**:
```bash
docker compose up backend
```

**Mobile Development**:
```bash
cd mobile
npx expo start
```

### Common Development Tasks

**Rebuild Agent with Code Changes**:
```bash
docker compose down && docker compose build --no-cache agent && docker compose up agent
```

**View Agent Logs**:
```bash
docker compose logs -f agent
```

**Mobile App Development**:
```bash
cd mobile
npx expo start --clear    # Clear cache
```

## ğŸ”§ Configuration

### LiveKit Setup

1. **LiveKit Cloud** (Recommended):
   - Sign up at [LiveKit Cloud](https://cloud.livekit.io/)
   - Create a new project
   - Get WebSocket URL and API credentials
   - Update `.env` file with your values

2. **Local LiveKit Server**:
   - Download from [LiveKit Releases](https://github.com/livekit/livekit/releases)
   - Run: `./livekit-server --dev`
   - Use `ws://localhost:7880` as URL

### OpenAI Models

The system uses OpenAI for:
- **Speech-to-Text**: Converts user voice to text
- **Language Model**: `gpt-4o-mini` for conversation processing
- **Text-to-Speech**: Converts AImee's responses to voice

### Mobile App Configuration

Update `mobile/app/lib/config.ts` if needed:
- LiveKit server URL
- JWT token for room access (for development)
- Room and participant settings

## ğŸ“‹ Testing

### Voice Functionality Testing

**Requirements**:
- Physical device (voice doesn't work in simulators)
- Stable internet connection
- Microphone permissions granted

**Test Flow**:
1. Start the voice agent: `docker compose up agent`
2. Deploy mobile app to physical device
3. Connect to AImee and verify automatic greeting
4. Test mute/unmute functionality
5. Have a conversation to verify speech-to-speech pipeline

**Expected Behavior**:
- AImee greets automatically when you join
- Voice recognition works with <200ms latency
- Mute button properly controls microphone state
- Natural conversation flow with tour guide personality

### Multi-Device Testing

Connect multiple devices to the same room to test:
- Multiple users hearing AImee simultaneously
- Audio quality with multiple participants
- Room management and participant handling

## ğŸ› Troubleshooting

### Agent Won't Start
- Check Docker is running: `docker --version`
- Verify environment variables in `.env` file
- Clear Docker cache: `docker system prune -f`
- Check agent logs: `docker compose logs agent`

### Mobile App Connection Issues
- Verify LiveKit credentials are correct
- Ensure device has internet connectivity
- Check mobile app has microphone permissions
- Confirm you're using a physical device (not simulator)

### No Voice Recognition
- Grant microphone permissions to the app
- Test with different devices to isolate hardware issues
- Check LiveKit room connection in app status log
- Verify OpenAI API key is valid

### Audio Quality Issues
- Test with different network conditions
- Check device volume levels
- Verify LiveKit server connectivity
- Review audio session configuration

## ğŸ“š Documentation

- **Phase 1 Testing Guide**: `mobile/PHASE_1_TESTING.md` - Detailed testing instructions
- **Development Guide**: `CLAUDE.md` - Architecture and commands for AI assistants
- **LiveKit Documentation**: [LiveKit Docs](https://docs.livekit.io/)
- **OpenAI API Reference**: [OpenAI API Docs](https://platform.openai.com/docs)

## ğŸ”„ Project Phases

- **Phase 1**: âœ… Basic LiveKit audio loopback
- **Phase 2-5**: âœ… OpenAI integration and multi-agent backend
- **Phase 6**: âœ… Real-time voice conversations with LiveKit Agents
- **Future**: Enhanced tour guide features, location integration, multi-language support

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Test voice functionality on physical devices
4. Ensure Docker services build correctly
5. Submit pull request with detailed description

## ğŸ“„ License

This project is for educational and demonstration purposes. Please ensure you have appropriate licenses for OpenAI API usage and LiveKit services.